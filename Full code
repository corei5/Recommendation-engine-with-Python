
# coding: utf-8

# In[1]:

from numpy import *

num_movies=10
num_users=5

ratings=random.randint(11,size=(num_movies,num_users))
print ratings


# In[2]:

#Hear output 1 for rating the movie, 0 for not rating the movie
#if rating is not equal to 0 make them 1
did_rate= (ratings!=0)*1
print did_rate


# In[3]:

#rating all movies
movie_rating= zeros((num_movies,1))
print movie_rating


# In[4]:

#rating some movies
movie_rating[0]=8
movie_rating[4]=7
movie_rating[7]=3
print movie_rating


# In[5]:

# add new coll(ratings)  and (did_rate) add binary of pervious ratings

ratings = append(movie_rating, ratings, axis = 1)
did_rate = append(((movie_rating != 0) * 1), did_rate, axis = 1)
print ratings
print did_rate


# In[6]:

a=[10,20,30]
avg = mean(a)
print avg


# In[7]:

#mean normalize something means always avarage is 0 
a = [10 - avg, 20 - avg, 30 - avg]
print a


# In[8]:

# a function that normalizes a dataset

def normalize_ratings(ratings, did_rate):
    num_movies = ratings.shape[0]
    
    ratings_mean = zeros(shape = (num_movies, 1))
    ratings_norm = zeros(shape = ratings.shape)
    
    for i in range(num_movies): 
        # Get all the indexes where there is a 1
        idx = where(did_rate[i] == 1)[0]
        #  Calculate mean rating of ith movie only from user's that gave a rating
        ratings_mean[i] = mean(ratings[i, idx])
        ratings_norm[i, idx] = ratings[i, idx] - ratings_mean[i]
    
    return ratings_norm, ratings_mean


# In[9]:

# Normalize ratings

ratings, ratings_mean = normalize_ratings(ratings, did_rate)


# In[10]:

# Update some key variables now

num_users = ratings.shape[1]
num_features = 3


# In[11]:

# Simple explanation of what it means to 'vectorize' a linear regression

X = array([[1, 2], [1, 5], [1, 9]])
Theta = array([[0.23], [0.34]])
print X


# In[12]:

print Theta


# In[13]:

#X is movie features
#Theta is user_prefs
Y = X.dot(Theta)
print Y


# In[14]:

# Initialize Parameters theta (user_prefs), X (movie_features)

movie_features = random.randn( num_movies, num_features )
user_prefs = random.randn( num_users, num_features )
initial_X_and_theta = r_[movie_features.T.flatten(), user_prefs.T.flatten()]


# In[15]:

print movie_features


# In[16]:

print user_prefs


# In[17]:

print initial_X_and_theta


# In[18]:

initial_X_and_theta.shape


# In[19]:

def unroll_params(X_and_theta, num_users, num_movies, num_features):
	# Retrieve the X and theta matrixes from X_and_theta, based on their dimensions (num_features, num_movies, num_movies)
	# --------------------------------------------------------------------------------------------------------------
	# Get the first 30 (10 * 3) rows in the 48 X 1 column vector
	first_30 = X_and_theta[:num_movies * num_features]
	# Reshape this column vector into a 10 X 3 matrix
	X = first_30.reshape((num_features, num_movies)).transpose()
	# Get the rest of the 18 the numbers, after the first 30
	last_18 = X_and_theta[num_movies * num_features:]
	# Reshape this column vector into a 6 X 3 matrix
	theta = last_18.reshape(num_features, num_users ).transpose()
	return X, theta


# In[20]:

def calculate_gradient(X_and_theta, ratings, did_rate, num_users, num_movies, num_features, reg_param):
	X, theta = unroll_params(X_and_theta, num_users, num_movies, num_features)
	
	# we multiply by did_rate because we only want to consider observations for which a rating was given
	difference = X.dot( theta.T ) * did_rate - ratings
	X_grad = difference.dot( theta ) + reg_param * X
	theta_grad = difference.T.dot( X ) + reg_param * theta
	
	# wrap the gradients back into a column vector 
	return r_[X_grad.T.flatten(), theta_grad.T.flatten()]


# In[23]:

def calculate_cost(X_and_theta, ratings, did_rate, num_users, num_movies, num_features, reg_param):
	X, theta = unroll_params(X_and_theta, num_users, num_movies, num_features)
	
	# we multiply (element-wise) by did_rate because we only want to consider observations for which a rating was given
	cost = sum( (X.dot( theta.T ) * did_rate - ratings) ** 2 ) / 2
	# '**' means an element-wise power
	regularization = (reg_param / 2) * (sum( theta**2 ) + sum(X**2))
	return cost + regularization


# In[33]:

# import these for advanced optimizations (like gradient descent)
from scipy import optimize

# regularization paramater
reg_param=30

# perform gradient descent, find the minimum cost (sum of squared errors) and optimal values of X (movie_features) and Theta (user_prefs)
minimized_cost_and_optimal_params = optimize.fmin_cg(calculate_cost, fprime=calculate_gradient, x0=initial_X_and_theta, 								args=(ratings, did_rate, num_users, num_movies, num_features, reg_param), maxiter=100, disp=True, full_output=True ) 



# In[24]:

cost, optimal_movie_features_and_user_prefs = minimized_cost_and_optimal_params[1], minimized_cost_and_optimal_params[0]


# In[34]:

print movie_features


# In[35]:

print user_prefs


# In[27]:

# Make some predictions (movie recommendations). Dot product

all_predictions = movie_features.dot( user_prefs.T )


# In[28]:

print all_predictions


# In[29]:

# add back the ratings_mean column vector to my (our) predictions

predictions = all_predictions[:, 0:1] + ratings_mean


# In[32]:

print ratings


# In[36]:

print predictions


# In[ ]:



